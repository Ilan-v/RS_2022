{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_raw=pd.read_csv('data/train.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spliting the data into train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = train_set_raw.groupby('UserID').sample(frac=0.8, random_state=42)\n",
    "# take the rest of the data as validation set\n",
    "df_val = train_set_raw[~train_set_raw.index.isin(df_train.index)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of items in train set: 3682\n",
      "Number of items not in train set that will be moved: 23\n"
     ]
    }
   ],
   "source": [
    "items_list = list(train_set_raw['ItemID'].unique())\n",
    "train_items_list = list(df_train['ItemID'].unique())\n",
    "items_not_in_train = set(items_list) - set(train_items_list)\n",
    "print(f'Number of items in train set: {len(train_items_list)}')\n",
    "print(f'Number of items not in train set that will be moved: {len(items_not_in_train)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move items that are not in the train set from the validation set\n",
    "moving_rows = df_val[df_val['ItemID'].isin(items_not_in_train)].groupby('ItemID').sample(1, random_state=42)\n",
    "df_val = df_val[~df_val.index.isin(moving_rows.index)]\n",
    "df_train = pd.concat([df_train, moving_rows])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of items not in train set after moving: 0\n"
     ]
    }
   ],
   "source": [
    "train_items_list = list(df_train['ItemID'].unique())\n",
    "items_not_in_train = set(items_list) - set(train_items_list)\n",
    "print(f'Number of items not in train set after moving: {len(items_not_in_train)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users in train set: 6040\n"
     ]
    }
   ],
   "source": [
    "users_list = list(train_set_raw['UserID'].unique())\n",
    "print(f'Number of users in train set: {len(users_list)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the train and validation data sets with negative and positive samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_items_dict_train = create_user_items_dict(df_train)\n",
    "user_items_dict_val = create_user_items_dict(df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_probability_dict = create_item_popularity_dict(train_set_raw)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load negative samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train set\n",
    "train_negative_random = load_negative_samples(user_items_dict_train, items_list, 'train', 'random')\n",
    "train_negative_popularity = load_negative_samples(user_items_dict_train, items_list, 'train', 'popularity', item_probability_dict)\n",
    "# validation set\n",
    "val_negative_random = load_negative_samples(user_items_dict_val, items_list, 'validation', 'random')\n",
    "val_negative_popularity = load_negative_samples(user_items_dict_val, items_list, 'validation', 'popularity', item_probability_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating datasets for training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6040/6040 [01:04<00:00, 93.14it/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1580992, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = create_dataset(train_negative_random, df_train)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(  train_df: pd.DataFrame,\n",
    "                    user_items_dict_validation: dict,\n",
    "                    negative_samples_validation: dict,\n",
    "                    user_list: list,\n",
    "                    items_list: list,\n",
    "                    alpha_item: float,\n",
    "                    alpha_user: float,\n",
    "                    epochs: int,\n",
    "                    k: int,\n",
    "                    lr: float,\n",
    "                    ) -> tuple:\n",
    "    \n",
    "    items_embeddings = create_embeddings(items_list, alpha_item, k)\n",
    "    users_embeddings = create_embeddings(user_list, alpha_user, k)\n",
    "    train = train_df.values\n",
    "    for e in range(epochs):\n",
    "        np.random.shuffle(train)\n",
    "        for user, item, rating in tqdm(train, desc=f'Epoch {e+1}'):\n",
    "            prediction = sigmoid(np.dot(users_embeddings[user], items_embeddings[item]))\n",
    "            error = rating - prediction\n",
    "            users_embeddings[user] += lr * error * items_embeddings[item] - alpha_user * users_embeddings[user]\n",
    "            items_embeddings[item] += lr * error * users_embeddings[user] - alpha_item * items_embeddings[item]\n",
    "    \n",
    "    return users_embeddings, items_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1580992/1580992 [00:21<00:00, 72495.96it/s]\n",
      "Epoch 2: 100%|██████████| 1580992/1580992 [00:21<00:00, 72690.07it/s]\n"
     ]
    }
   ],
   "source": [
    "users_embeddings, items_embeddings = training_loop( df,\n",
    "                                                    user_items_dict_val, val_negative_random,\n",
    "                                                    users_list, items_list,\n",
    "                                                    alpha_item = 0.01,\n",
    "                                                    alpha_user = 0.01,\n",
    "                                                    epochs = 2,\n",
    "                                                    k = 16,\n",
    "                                                    lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_on_test_set(row:pd.Series, users_embeddings:dict, items_embeddings:dict)->pd.Series:\n",
    "    user = row['UserID']\n",
    "    item_1 = row['Item1']\n",
    "    item_2 = row['Item2']\n",
    "\n",
    "    item_1_score = np.dot(users_embeddings[user], items_embeddings[item_1])\n",
    "    item_2_score = np.dot(users_embeddings[user], items_embeddings[item_2])\n",
    "\n",
    "    if item_1_score > item_2_score:\n",
    "        row['prediction'] = 0\n",
    "    else:\n",
    "        row['prediction'] = 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d0d24260c26781aab6a6247b3ae992ece4f26fd75ea3713b7a84756a27d5e272"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
